{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sedimentation Rate Analysis\n",
    "\n",
    "### Load dataset and declare indices of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import geo_preprocess3\n",
    "from tabulate import tabulate\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# load data\n",
    "data = np.genfromtxt('alldata_new_decomp', delimiter='')\n",
    "\n",
    "# define column index for 19 variables\n",
    "lon_ind = 0\n",
    "lat_ind = 1\n",
    "sedthick_ind = 2\n",
    "sedrate_ind = 3   \n",
    "age_ind = 4\n",
    "passive_dis_ind = 5\n",
    "amazon_dis_ind = 6\n",
    "congo_dis_ind = 7\n",
    "gange_dis_ind = 8\n",
    "godava_dis_ind = 9\n",
    "indus_dis_ind = 10\n",
    "magdalena_dis_ind = 11\n",
    "mahan_dis_ind = 12\n",
    "missi_dis_ind = 13\n",
    "narma_dis_ind = 14\n",
    "niger_dis_ind = 15\n",
    "orin_dis_ind = 16\n",
    "paleo_dis_ind = 17\n",
    "parana_dis_ind = 18\n",
    "\n",
    "river_indices = np.array([amazon_dis_ind, congo_dis_ind, gange_dis_ind, godava_dis_ind, indus_dis_ind, \n",
    "                          magdalena_dis_ind, mahan_dis_ind, missi_dis_ind, narma_dis_ind, niger_dis_ind,\n",
    "                          orin_dis_ind, paleo_dis_ind, parana_dis_ind])\n",
    "\n",
    "river_names = np.array(['Amazon', 'Congo', 'Ganges-Bramaputra', 'Godavari-Krishna', 'Indus',\n",
    "                        'Magdalena', 'Mahanadi', 'Mississipi', 'Narma', 'Niger', 'Orinoco',\n",
    "                        'Paleo-Congo', 'Parana'])\n",
    "\n",
    "print(river_indices)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Declare the regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# number of splits for LongFold cross validation\n",
    "n_splits = 3\n",
    "\n",
    "# regressor\n",
    "regressor = Pipeline(steps=[('stand', StandardScaler()),\n",
    "                            ('poly', PolynomialFeatures(degree=3)),\n",
    "                            ('linear', Lasso(alpha=0.01))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Remove records where rate is nan, age is nan, and distance to passive is nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove records where thick is zero\n",
    "y = data[:, sedthick_ind]\n",
    "data = data[~(y == 0)]\n",
    "\n",
    "# remove records where age is nan\n",
    "y = data[:, age_ind]\n",
    "data = data[~np.isnan(y)]\n",
    "\n",
    "# remove records where distance to passive margin is nan\n",
    "y = data[:, passive_dis_ind]\n",
    "data = data[~np.isnan(y)]\n",
    "\n",
    "# remove records where sediment rate is nan or 0\n",
    "sedrate = data[:, sedrate_ind]\n",
    "index = (~np.isnan(sedrate)) & (~(sedrate == 0))\n",
    "data = data[index]\n",
    "\n",
    "# the final dataset has dimension as follows\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot histogram for sedimentation rate and log sedimentation rate\n",
    "f, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.hist(data[:, [sedrate_ind]], color=\"#3F5D7D\", bins=15)\n",
    "ax2.hist(np.log(data[:, [sedrate_ind]]), color=\"#3F5D7D\", bins=15)\n",
    "ax1.set_xlabel('sedimentation rate')\n",
    "ax1.set_ylabel('frequency')\n",
    "ax2.set_xlabel('log sedimentation rate')\n",
    "ax1.set_title('Histogram of rate')\n",
    "ax2.set_title('Histogram of log rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_irivers(data, river_indices):\n",
    "    \"\"\"Generate inverse of selected rivers from given data.\"\"\"\n",
    "    \n",
    "    rivers = data[:, river_indices]\n",
    "    \n",
    "    # mask rivers with distance greater than 1500km\n",
    "    rivers[rivers > 1500.0] = np.nan\n",
    "\n",
    "    rivers[np.isnan(rivers)] = np.inf\n",
    "    \n",
    "    return 1.0 / rivers\n",
    "\n",
    "\n",
    "def plot_goodness_fit(lon, lat, yactual, ypred, ypred_no_rivers, time):\n",
    "    \"\"\"Generate various plots of goodness of fit.\"\"\"\n",
    "    # scatterplot of ypred and yactual\n",
    "    geo_preprocess3.feature_scatter(yactual, ypred, \n",
    "                                    title = 'Fit with rivers ' + time,\n",
    "                                   xlim1=-4,\n",
    "                                   xlim2=3,\n",
    "                                   ylim1=-4,\n",
    "                                   ylim2=3)\n",
    "    # scatterplot of ypred_no_rivers and yactual\n",
    "    geo_preprocess3.feature_scatter(yactual, ypred_no_rivers, \n",
    "                                    title = 'Fit without rivers ' + time,\n",
    "                                   xlim1=-4,\n",
    "                                   xlim2=3,\n",
    "                                   ylim1=-4,\n",
    "                                   ylim2=3)\n",
    "\n",
    "    # global map of y actual\n",
    "    geo_preprocess3.draw_global(c=yactual, \n",
    "                                title='actual log sediment rate ' + time,\n",
    "                                longitude=lon, latitude=lat, \n",
    "                                vmin=-4, \n",
    "                                vmax=3)\n",
    "    \n",
    "    # global map of y predicted\n",
    "    geo_preprocess3.draw_global(c=ypred, \n",
    "                           title='predicted log sediment rate with rivers ' + time,\n",
    "                           longitude=lon, latitude=lat, \n",
    "                           vmin=-4, \n",
    "                           vmax=3)\n",
    "\n",
    "    # global map of y predicted without rivers\n",
    "    geo_preprocess3.draw_global(c=ypred_no_rivers, \n",
    "                           title='predicted log sediment rate without rivers ' + time,\n",
    "                           longitude=lon, latitude=lat, \n",
    "                           vmin=-4, \n",
    "                           vmax=3)\n",
    "\n",
    "    # ypred - ypred_no_rivers\n",
    "    geo_preprocess3.draw_global(c= (np.exp(ypred) - np.exp(ypred_no_rivers)), \n",
    "                       title='predicted rate with rivers minus predicted rate without rivers ' + time,\n",
    "                       longitude=lon, latitude=lat, \n",
    "                       vmin=-2, \n",
    "                       vmax=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train and Predict - with all rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.seterr(invalid='ignore')\n",
    "\n",
    "irivers = generate_irivers(data, river_indices)\n",
    "\n",
    "# data1 only has feature longitude, latitude, age and distance to passive margin\n",
    "data1 = data[:, [lon_ind, lat_ind, age_ind, passive_dis_ind]]\n",
    "\n",
    "# extract sedimentation rate\n",
    "sedrate = data[:, sedrate_ind]\n",
    "\n",
    "def compute_r2(weights):\n",
    "    nr2 = 0.0\n",
    "    \n",
    "    # square weights to make sure they are positive\n",
    "    weights = weights ** 2\n",
    "\n",
    "    # obtain weighted sum of inverse of distance to rivers\n",
    "    ws_river = np.sum(irivers * weights, axis=1)\n",
    "    \n",
    "    # integrate all features and target variable into one matrix - data2\n",
    "    data2 = np.c_[data1, ws_river, sedrate]\n",
    "    \n",
    "    # do regression \n",
    "    # - this is a function in file geo_preprocess3\n",
    "    # - it use longitude to do LongFold cross validation\n",
    "    # - logy=True means apply log transform to target variable y\n",
    "    ypred,_ = geo_preprocess3.regression(data=data2, \n",
    "                    regressor=regressor, \n",
    "                    n_splits=n_splits,\n",
    "                    lon_ind=lon_ind, \n",
    "                    lat_ind=lat_ind, \n",
    "                    y_ind=-1,\n",
    "                    logy=True)\n",
    "    \n",
    "    yactual = np.log(sedrate)\n",
    "    \n",
    "    # obtain negative r square of actual log rate and predicted log rate\n",
    "    nr2 = -1.0 * r2_score(yactual, ypred)\n",
    "    \n",
    "    # print nr2 to see the process of optimization\n",
    "    print(nr2)\n",
    "    return nr2\n",
    "\n",
    "\n",
    "\n",
    "# initial guess of weights; seed fix random number so that we can recover the result\n",
    "np.random.seed(0)\n",
    "w0 = np.random.random(13)\n",
    "\n",
    "# here I comment out the command for launching optmization, it takes long time to converge\n",
    "\n",
    "# res = minimize(fun=compute_r2,\n",
    "#                x0=w0,\n",
    "#                method='COBYLA',\n",
    "#                tol=1e-6,\n",
    "#                options={'maxiter': 10000,\n",
    "#                         'disp': True}\n",
    "# )\n",
    "# res.x\n",
    "# opt = res.x\n",
    "# opt_weights = opt ** 2\n",
    "# print(tabulate(np.vstack([river_names, opt_weights]).T))\n",
    "\n",
    "\n",
    "# This is the optimal weights from optimization\n",
    "opt_weights = np.array([\n",
    "        0.82880631,\n",
    "        0.17390902,\n",
    "        0.35638273,\n",
    "        0.36284359,\n",
    "        0.03679376,\n",
    "        0.02927179,\n",
    "        0.29118327,\n",
    "        0.68002453,\n",
    "        1.34912871,\n",
    "        0.178907,\n",
    "        0.32999625,\n",
    "        0.08140008,\n",
    "        0.60066065\n",
    "    ])\n",
    "\n",
    "# use opt_weights to get optimal weighted sum of inverse of distance to rivers\n",
    "ws_river = np.sum(irivers * opt_weights, 1)\n",
    "\n",
    "# re-define data2 with optimal weighted summation\n",
    "data2 = np.c_[data1, ws_river, sedrate]\n",
    "\n",
    "# regression, with optimal weighted sum of inverse of distance to rivers\n",
    "# return predicted log rate and trained regressor\n",
    "ypred, _ =  geo_preprocess3.regression(data=data2, \n",
    "                                        regressor=regressor, \n",
    "                                        n_splits=3,\n",
    "                                        lon_ind=lon_ind, \n",
    "                                        lat_ind=lat_ind, \n",
    "                                        y_ind=-1,\n",
    "                                        logy=True)\n",
    "\n",
    "# regression, without distance to river features\n",
    "# remove data points with distance less than 1500km\n",
    "indices_remain = np.any(irivers == 0, 1)\n",
    "data2_no_rivers = np.c_[data1[indices_remain], sedrate[indices_remain]]\n",
    "\n",
    "# train regressor given dataset with data points whose distance less than 1500 removed\n",
    "_, regressor_trained =  geo_preprocess3.regression(data=data2_no_rivers, \n",
    "                                        regressor=regressor, \n",
    "                                        n_splits=3,\n",
    "                                        lon_ind=lon_ind, \n",
    "                                        lat_ind=lat_ind, \n",
    "                                        y_ind=-1,\n",
    "                                        logy=True)\n",
    "# predict y given all data points\n",
    "ypred_no_rivers = geo_preprocess3.predict(data1, regressor_trained, lon_ind=lon_ind,\n",
    "                                         lat_ind=lat_ind)\n",
    "\n",
    "# extract longitude, latitude and sedrate for plots\n",
    "lon = data1[:,lon_ind]\n",
    "lat = data1[:,lat_ind]\n",
    "yactual = np.log(sedrate)\n",
    "\n",
    "# generate various plots of goodness of fit\n",
    "plot_goodness_fit(lon, lat, yactual, ypred, ypred_no_rivers, 'ignore time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train and Predict - Present (exclude Paleo-Congo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "age = data[:, age_ind]\n",
    "\n",
    "# existed river indices\n",
    "c_river_indices = np.array([amazon_dis_ind, congo_dis_ind, gange_dis_ind, godava_dis_ind, indus_dis_ind, \n",
    "                          magdalena_dis_ind, mahan_dis_ind, missi_dis_ind, narma_dis_ind, niger_dis_ind,\n",
    "                          orin_dis_ind, parana_dis_ind])\n",
    "\n",
    "# extract subset of data so that the age is greater than 0.0\n",
    "period_index = (age > 0.0)\n",
    "datapd = data[period_index]\n",
    "\n",
    "# generate inverse of rivers\n",
    "irivers = generate_irivers(datapd, c_river_indices)\n",
    "\n",
    "# data1 only has feature longitude, latitude, age and distance to passive margin\n",
    "data1 = datapd[:, [lon_ind, lat_ind, age_ind, passive_dis_ind]]\n",
    "\n",
    "# extract sedimentation rate\n",
    "sedrate = datapd[:, sedrate_ind]\n",
    "\n",
    "def compute_r2(weights):\n",
    "    nr2 = 0.0\n",
    "    weights = weights ** 2\n",
    "    ws_river = np.sum(irivers * weights, axis=1)\n",
    "    data2 = np.c_[data1, ws_river, sedrate]\n",
    "    ypred,_ = geo_preprocess3.regression(data=data2, \n",
    "                    regressor=regressor, \n",
    "                    n_splits=n_splits,\n",
    "                    lon_ind=lon_ind, \n",
    "                    lat_ind=lat_ind, \n",
    "                    y_ind=-1,\n",
    "                    logy=True)\n",
    "    \n",
    "    yactual = np.log(sedrate)\n",
    "    nr2 = -1.0 * r2_score(yactual, ypred)\n",
    "    print(nr2)\n",
    "    return nr2\n",
    "\n",
    "# initial guess of weights; seed fix random number so that we can recover the result\n",
    "np.random.seed(0)\n",
    "w0 = np.random.random(len(c_river_indices))\n",
    "\n",
    "# here I comment out the command for launching optmization, it takes long time to converge\n",
    "\n",
    "# res = minimize(fun=compute_r2,\n",
    "#                x0=w0,\n",
    "#                method='COBYLA',\n",
    "#                tol=1e-6,\n",
    "#                options={'maxiter': 10000,\n",
    "#                         'disp': True}\n",
    "# )\n",
    "# res.x\n",
    "# opt = res.x\n",
    "# opt_weights = opt ** 2\n",
    "# print(tabulate(np.vstack([river_names[c_river_indices - 6], opt]).T))\n",
    "\n",
    "\n",
    "# This is the optimal weights from optimization\n",
    "opt_weights = np.array([\n",
    "        0.23177196,\n",
    "        0.37932296,\n",
    "        3.23755246,\n",
    "        0.49370859,\n",
    "        0.3206787,\n",
    "        0.44191118,\n",
    "        0.25530889,\n",
    "        0.74211505,\n",
    "        0.5854683,\n",
    "        0.11142845,\n",
    "        0.45804064,\n",
    "        0.28009498\n",
    "    ])\n",
    "\n",
    "# use opt_weights to get optimal weighted sum of inverse of distance to rivers\n",
    "ws_river = np.sum(irivers * opt_weights, 1)\n",
    "\n",
    "# re-define data2 with optimal weighted summation\n",
    "data2 = np.c_[data1, ws_river, sedrate]\n",
    "\n",
    "# regression, with optimal weighted sum of inverse of distance to rivers\n",
    "# return predicted log rate and trained regressor\n",
    "ypred, _ =  geo_preprocess3.regression(data=data2, \n",
    "                                        regressor=regressor, \n",
    "                                        n_splits=3,\n",
    "                                        lon_ind=lon_ind, \n",
    "                                        lat_ind=lat_ind, \n",
    "                                        y_ind=-1,\n",
    "                                        logy=True)\n",
    "\n",
    "# regression, without distance to river features\n",
    "# remove data points with distance less than 1500km\n",
    "indices_remain = np.any(irivers == 0, 1)\n",
    "data2_no_rivers = np.c_[data1[indices_remain], sedrate[indices_remain]]\n",
    "\n",
    "# train regressor given dataset with data points whose distance less than 1500 removed\n",
    "_, regressor_trained =  geo_preprocess3.regression(data=data2_no_rivers, \n",
    "                                        regressor=regressor, \n",
    "                                        n_splits=3,\n",
    "                                        lon_ind=lon_ind, \n",
    "                                        lat_ind=lat_ind, \n",
    "                                        y_ind=-1,\n",
    "                                        logy=True)\n",
    "# predict y given all data points\n",
    "ypred_no_rivers = geo_preprocess3.predict(data1, regressor_trained, lon_ind=lon_ind,\n",
    "                                         lat_ind=lat_ind)\n",
    "\n",
    "# extract longitude, latitude and sedrate for plots\n",
    "lon = data1[:,lon_ind]\n",
    "lat = data1[:,lat_ind]\n",
    "yactual = np.log(sedrate)\n",
    "\n",
    "# generate various plots of goodness of fit\n",
    "plot_goodness_fit(lon, lat, yactual, ypred, ypred_no_rivers, 'present')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train and Predict - 26Ma (exclude Paleo-Congo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# existed river indices\n",
    "c_river_indices = np.array([gange_dis_ind, godava_dis_ind, indus_dis_ind, \n",
    "                          magdalena_dis_ind, mahan_dis_ind, missi_dis_ind, narma_dis_ind, niger_dis_ind,\n",
    "                          parana_dis_ind])\n",
    "\n",
    "# extract subset of data so that the age is greater than 26.0\n",
    "period_index = (age > 26.0)\n",
    "datapd = data[period_index]\n",
    "\n",
    "# generate inverse of rivers\n",
    "irivers = generate_irivers(datapd, c_river_indices)\n",
    "\n",
    "# data1 only has feature longitude, latitude, age and distance to passive margin\n",
    "data1 = datapd[:, [lon_ind, lat_ind, age_ind, passive_dis_ind]]\n",
    "\n",
    "# extract sedimentation rate\n",
    "sedrate = datapd[:, sedrate_ind]\n",
    "\n",
    "def compute_r2(weights):\n",
    "    nr2 = 0.0\n",
    "    weights = weights ** 2\n",
    "    ws_river = np.sum(irivers * weights, axis=1)\n",
    "    data2 = np.c_[data1, ws_river, sedrate]\n",
    "    ypred,_ = geo_preprocess3.regression(data=data2, \n",
    "                    regressor=regressor, \n",
    "                    n_splits=n_splits,\n",
    "                    lon_ind=lon_ind, \n",
    "                    lat_ind=lat_ind, \n",
    "                    y_ind=-1,\n",
    "                    logy=True)\n",
    "    \n",
    "    yactual = np.log(sedrate)\n",
    "    nr2 = -1.0 * r2_score(yactual, ypred)\n",
    "    print(nr2)\n",
    "    return nr2\n",
    "\n",
    "# initial guess of weights; seed fix random number so that we can recover the result\n",
    "np.random.seed(0)\n",
    "w0 = np.random.random(len(c_river_indices))\n",
    "\n",
    "# here I comment out the command for launching optmization, it takes long time to converge\n",
    "\n",
    "# res = minimize(fun=compute_r2,\n",
    "#                x0=w0,\n",
    "#                method='COBYLA',\n",
    "#                tol=1e-6,\n",
    "#                options={'maxiter': 10000,\n",
    "#                         'disp': True}\n",
    "# )\n",
    "# res.x\n",
    "# opt = res.x\n",
    "# opt_weights = opt ** 2\n",
    "# print(tabulate(np.vstack([river_names[c_river_indices - 6], opt_weights]).T))\n",
    "\n",
    "# This is the optimal weights from optimization\n",
    "opt_weights = np.array([\n",
    "        0.519334,\n",
    "        0.943441,\n",
    "        0.943441,\n",
    "        0.77053,\n",
    "        0.944752,\n",
    "        2.15442,\n",
    "        0.329905,\n",
    "        0.86657,\n",
    "        1.51828\n",
    "    ])\n",
    "\n",
    "# use opt_weights to get optimal weighted sum of inverse of distance to rivers\n",
    "ws_river = np.sum(irivers * opt_weights, 1)\n",
    "\n",
    "# re-define data2 with optimal weighted summation\n",
    "data2 = np.c_[data1, ws_river, sedrate]\n",
    "\n",
    "# regression, with optimal weighted sum of inverse of distance to rivers\n",
    "# return predicted log rate and trained regressor\n",
    "ypred, _ =  geo_preprocess3.regression(data=data2, \n",
    "                                        regressor=regressor, \n",
    "                                        n_splits=3,\n",
    "                                        lon_ind=lon_ind, \n",
    "                                        lat_ind=lat_ind, \n",
    "                                        y_ind=-1,\n",
    "                                        logy=True)\n",
    "\n",
    "# regression, without distance to river features\n",
    "# remove data points with distance less than 1500km\n",
    "indices_remain = np.any(irivers == 0, 1)\n",
    "data2_no_rivers = np.c_[data1[indices_remain], sedrate[indices_remain]]\n",
    "\n",
    "# train regressor given dataset with data points whose distance less than 1500 removed\n",
    "_, regressor_trained =  geo_preprocess3.regression(data=data2_no_rivers, \n",
    "                                        regressor=regressor, \n",
    "                                        n_splits=3,\n",
    "                                        lon_ind=lon_ind, \n",
    "                                        lat_ind=lat_ind, \n",
    "                                        y_ind=-1,\n",
    "                                        logy=True)\n",
    "# predict y given all data points\n",
    "ypred_no_rivers = geo_preprocess3.predict(data1, regressor_trained, lon_ind=lon_ind,\n",
    "                                         lat_ind=lat_ind)\n",
    "\n",
    "# extract longitude, latitude and sedrate for plots\n",
    "lon = data1[:,lon_ind]\n",
    "lat = data1[:,lat_ind]\n",
    "yactual = np.log(sedrate)\n",
    "\n",
    "# generate various plots of goodness of fit\n",
    "plot_goodness_fit(lon, lat, yactual, ypred, ypred_no_rivers, '26Ma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train and Predict - 56Ma (only Parana, Paleo-Congo, Niger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# existed river indices\n",
    "c_river_indices = np.array([niger_dis_ind,paleo_dis_ind, parana_dis_ind])\n",
    "\n",
    "\n",
    "# extract subset of data so that the age is greater than 26.0\n",
    "period_index = (age > 56.0)\n",
    "datapd = data[period_index]\n",
    "\n",
    "# generate inverse of rivers\n",
    "irivers = generate_irivers(datapd, c_river_indices)\n",
    "\n",
    "# data1 only has feature longitude, latitude, age and distance to passive margin\n",
    "data1 = datapd[:, [lon_ind, lat_ind, age_ind, passive_dis_ind]]\n",
    "\n",
    "# extract sedimentation rate\n",
    "sedrate = datapd[:, sedrate_ind]\n",
    "\n",
    "def compute_r2(weights):\n",
    "    nr2 = 0.0\n",
    "    weights = weights ** 2\n",
    "    ws_river = np.sum(irivers * weights, axis=1)\n",
    "    data2 = np.c_[data1, ws_river, sedrate]\n",
    "    ypred,_ = geo_preprocess3.regression(data=data2, \n",
    "                    regressor=regressor, \n",
    "                    n_splits=n_splits,\n",
    "                    lon_ind=lon_ind, \n",
    "                    lat_ind=lat_ind, \n",
    "                    y_ind=-1,\n",
    "                    logy=True)\n",
    "    \n",
    "    yactual = np.log(sedrate)\n",
    "    nr2 = -1.0 * r2_score(yactual, ypred)\n",
    "    print(nr2)\n",
    "    return nr2\n",
    "\n",
    "# initial guess of weights; seed fix random number so that we can recover the result\n",
    "np.random.seed(0)\n",
    "w0 = np.random.random(len(c_river_indices))\n",
    "\n",
    "# here I comment out the command for launching optmization, it takes long time to converge\n",
    "\n",
    "# res = minimize(fun=compute_r2,\n",
    "#                x0=w0,\n",
    "#                method='COBYLA',\n",
    "#                tol=1e-6,\n",
    "#                options={'maxiter': 10000,\n",
    "#                         'disp': True}\n",
    "# )\n",
    "# res.x\n",
    "# opt = res.x\n",
    "# opt_weights = opt ** 2\n",
    "# print(tabulate(np.vstack([river_names[c_river_indices - 6], opt_weights]).T))\n",
    "\n",
    "\n",
    "\n",
    "# This is the optimal weights from optimization\n",
    "opt_weights = np.array([\n",
    "        0.927084,\n",
    "        0.000577668,\n",
    "        3.88235\n",
    "    ])\n",
    "\n",
    "# use opt_weights to get optimal weighted sum of inverse of distance to rivers\n",
    "ws_river = np.sum(irivers * opt_weights, 1)\n",
    "\n",
    "# re-define data2 with optimal weighted summation\n",
    "data2 = np.c_[data1, ws_river, sedrate]\n",
    "\n",
    "# regression, with optimal weighted sum of inverse of distance to rivers\n",
    "# return predicted log rate and trained regressor\n",
    "ypred, _ =  geo_preprocess3.regression(data=data2, \n",
    "                                        regressor=regressor, \n",
    "                                        n_splits=3,\n",
    "                                        lon_ind=lon_ind, \n",
    "                                        lat_ind=lat_ind, \n",
    "                                        y_ind=-1,\n",
    "                                        logy=True)\n",
    "\n",
    "# regression, without distance to river features\n",
    "# remove data points with distance less than 1500km\n",
    "indices_remain = np.any(irivers == 0, 1)\n",
    "data2_no_rivers = np.c_[data1[indices_remain], sedrate[indices_remain]]\n",
    "\n",
    "# train regressor given dataset with data points whose distance less than 1500 removed\n",
    "_, regressor_trained =  geo_preprocess3.regression(data=data2_no_rivers, \n",
    "                                        regressor=regressor, \n",
    "                                        n_splits=3,\n",
    "                                        lon_ind=lon_ind, \n",
    "                                        lat_ind=lat_ind, \n",
    "                                        y_ind=-1,\n",
    "                                        logy=True)\n",
    "# predict y given all data points\n",
    "ypred_no_rivers = geo_preprocess3.predict(data1, regressor_trained, lon_ind=lon_ind,\n",
    "                                         lat_ind=lat_ind)\n",
    "\n",
    "# extract longitude, latitude and sedrate for plots\n",
    "lon = data1[:,lon_ind]\n",
    "lat = data1[:,lat_ind]\n",
    "yactual = np.log(sedrate)\n",
    "\n",
    "# generate various plots of goodness of fit\n",
    "plot_goodness_fit(lon, lat, yactual, ypred, ypred_no_rivers, '56Ma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feature Analysis - Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# regressor\n",
    "regressor = Pipeline(steps=[('stand', StandardScaler()),\n",
    "                            ('poly', PolynomialFeatures(degree=3)),\n",
    "                            ('linear', Lasso(alpha=0.01))])\n",
    "\n",
    "# global map of age\n",
    "age = data[:, age_ind]\n",
    "sedrate = data[:, sedrate_ind]\n",
    "geo_preprocess3.draw_global(c=age, \n",
    "                            title='Global map of age',\n",
    "                            longitude=data[:, lon_ind],\n",
    "                            latitude=data[:, lat_ind],\n",
    "                            vmin = 0,\n",
    "                            vmax=197, \n",
    "                            cmap='Blues')\n",
    "\n",
    "# learn relationship between age and sedrate\n",
    "regressor.fit(age.reshape(-1,1), np.log(sedrate))\n",
    "fea_min = np.min(age)\n",
    "fea_max = np.max(age)\n",
    "fea_query = np.linspace(fea_min, fea_max, 20)[:, np.newaxis]\n",
    "fea_pred = regressor.predict(fea_query)\n",
    "\n",
    "# scatterplot of age and log sedrate\n",
    "plt.plot(age, np.log(data[:, sedrate_ind]), 'go', alpha=0.05, lw=0)\n",
    "plt.plot(fea_query, fea_pred, color='b')\n",
    "plt.title('scatterplot of age and log sedrate with regression line')\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('log sedrate')\n",
    "plt.ylim([-6, 8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feature Analysis - Distance to passive margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# regressor\n",
    "regressor = Pipeline(steps=[('stand', StandardScaler()),\n",
    "                            ('poly', PolynomialFeatures(degree=3)),\n",
    "                            ('linear', Lasso(alpha=0.01))])\n",
    "\n",
    "# global map of distance to passive margine\n",
    "passive_dis = data[:, passive_dis_ind]\n",
    "sedrate = data[:, sedrate_ind]\n",
    "geo_preprocess3.draw_global(c=passive_dis, \n",
    "                            title='Global map of distance to passive margin',\n",
    "                            longitude=data[:, lon_ind],\n",
    "                            latitude=data[:, lat_ind],\n",
    "                            vmin = 0,\n",
    "                            vmax=8000,\n",
    "                            cmap='Blues')\n",
    "\n",
    "# learn relationship between distance to passive margine and sedrate\n",
    "regressor.fit(passive_dis.reshape(-1,1), np.log(sedrate))\n",
    "fea_min = np.min(passive_dis)\n",
    "fea_max = np.max(passive_dis)\n",
    "fea_query = np.linspace(fea_min, fea_max, 20)[:, np.newaxis]\n",
    "fea_pred = regressor.predict(fea_query)\n",
    "\n",
    "# scatterplot of distance to passive margine and log sedrate\n",
    "plt.plot(passive_dis, np.log(data[:, sedrate_ind]), 'go', alpha=0.05, lw=0)\n",
    "plt.plot(fea_query, fea_pred, color='b')\n",
    "plt.title('scatterplot of distance to passive margin and log sedrate with regression line')\n",
    "plt.xlabel('distance to passive margin')\n",
    "plt.ylabel('log sedrate')\n",
    "plt.ylim([-6, 8])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
